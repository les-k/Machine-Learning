{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1685294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c9fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "churn_data = pd.read_csv('Churn_Modelling.csv')\n",
    "insurance_data = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a74dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
      "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
      "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
      "      dtype='object')\n",
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(churn_data.columns)\n",
    "print(insurance_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542c4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns (CustomerId, Surname, and RowNumber)\n",
    "churn_data = churn_data.drop(['CustomerId', 'Surname', 'RowNumber'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f28ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(churn_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8204fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for Churn dataset\n",
    "churn_data = pd.get_dummies(churn_data, columns=['Gender', 'Geography'], drop_first=True)\n",
    "X_churn = churn_data.drop(['Exited'], axis=1)\n",
    "y_churn = churn_data['Exited']\n",
    "X_train_churn, X_test_churn, y_train_churn, y_test_churn = train_test_split(X_churn, y_churn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a087b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for Insurance dataset\n",
    "insurance_data = pd.get_dummies(insurance_data, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "X_insurance = insurance_data.drop(['charges'], axis=1)\n",
    "y_insurance = insurance_data['charges']\n",
    "X_train_insurance, X_test_insurance, y_train_insurance, y_test_insurance = train_test_split(X_insurance, y_insurance, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e6629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_churn = scaler.fit_transform(X_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c665af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_insurance = scaler.fit_transform(X_insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f816238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest (Churn): 0.8675\n",
      "Precision for Random Forest (Churn): 0.7758620689655172\n",
      "Recall for Random Forest (Churn): 0.4580152671755725\n",
      "F1-score for Random Forest (Churn): 0.576\n"
     ]
    }
   ],
   "source": [
    "# Homogeneous ensemble with Random Forest for Churn dataset\n",
    "rf_model_churn = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model_churn.fit(X_train_churn, y_train_churn)\n",
    "y_pred_churn = rf_model_churn.predict(X_test_churn)\n",
    "print('Accuracy for Random Forest (Churn):', accuracy_score(y_test_churn, y_pred_churn))\n",
    "print('Precision for Random Forest (Churn):', precision_score(y_test_churn, y_pred_churn))\n",
    "print('Recall for Random Forest (Churn):', recall_score(y_test_churn, y_pred_churn))\n",
    "print('F1-score for Random Forest (Churn):', f1_score(y_test_churn, y_pred_churn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914ca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e08ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable to categorical values\n",
    "y_train_insurance = pd.cut(y_train_insurance, bins=[-float(\"inf\"), 0.5, float(\"inf\")], labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41607c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest (Insurance): 1.0\n",
      "Precision for Random Forest (Insurance): 1.0\n",
      "Recall for Random Forest (Insurance): 1.0\n",
      "F1-score for Random Forest (insurance): 1.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_test_insurance_binary = (y_test_insurance >= threshold).astype(int)\n",
    "\n",
    "rf_model_insurance = RandomForestClassifier(random_state=42)\n",
    "rf_model_insurance.fit(X_train_insurance, y_train_insurance)\n",
    "y_pred_insurance = rf_model_insurance.predict(X_test_insurance)\n",
    "\n",
    "print('Accuracy for Random Forest (Insurance):', accuracy_score(y_test_insurance_binary, y_pred_insurance))\n",
    "print('Precision for Random Forest (Insurance):', precision_score(y_test_insurance_binary, y_pred_insurance))\n",
    "print('Recall for Random Forest (Insurance):', recall_score(y_test_insurance_binary, y_pred_insurance))\n",
    "print('F1-score for Random Forest (insurance):', f1_score(y_test_insurance_binary, y_pred_insurance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "498c418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Heterogeneous ensemble (Churn): 0.8075\n",
      "Precision for Heterogeneous ensemble (Churn): 0.6333333333333333\n",
      "Recall for Heterogeneous ensemble (Churn): 0.04834605597964377\n",
      "F1-score for Heterogeneous ensemble (Churn): 0.08983451536643025\n"
     ]
    }
   ],
   "source": [
    "# Heterogeneous ensemble for Churn dataset\n",
    "dt_model_churn = DecisionTreeClassifier(random_state=42)\n",
    "lr_model_churn = LogisticRegression(random_state=42)\n",
    "svm_model_churn = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "hetero_model_churn = VotingClassifier(\n",
    "    estimators=[('dt', dt_model_churn), ('lr', lr_model_churn), ('svm', svm_model_churn)], \n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "hetero_model_churn.fit(X_train_churn, y_train_churn)\n",
    "y_pred_churn = hetero_model_churn.predict(X_test_churn)\n",
    "\n",
    "print('Accuracy for Heterogeneous ensemble (Churn):', accuracy_score(y_test_churn, y_pred_churn))\n",
    "print('Precision for Heterogeneous ensemble (Churn):', precision_score(y_test_churn, y_pred_churn))\n",
    "print('Recall for Heterogeneous ensemble (Churn):', recall_score(y_test_churn, y_pred_churn))\n",
    "print('F1-score for Heterogeneous ensemble (Churn):', f1_score(y_test_churn, y_pred_churn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9efdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heterogeneous ensemble for Insurance dataset\n",
    "# define models\n",
    "dt_model_insurance = DecisionTreeClassifier(random_state=42)\n",
    "lr_model_insurance = LogisticRegression(random_state=42)\n",
    "svm_model_insurance = SVC(kernel='rbf', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3bd90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define heterogeneous ensemble model\n",
    "hetero_model_insurance = VotingClassifier(estimators=[\n",
    "    ('dt', dt_model_insurance), \n",
    "    ('lr', lr_model_insurance), \n",
    "    ('svm', svm_model_insurance)], \n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f4465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ae8fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a938a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random binary classification data\n",
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8fec272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are at least two unique classes in the data\n",
    "if len(np.unique(y)) < 2:\n",
    "    raise ValueError(\"The data must contain at least two classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "537c94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af7c0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a voting classifier using logistic regression and decision tree\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "voting_clf = VotingClassifier(estimators=[('lr', logistic), ('dt', tree)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "728fad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ef81d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "accuracy = voting_clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab680ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 1\n"
     ]
    }
   ],
   "source": [
    "# check number of unique values in y\n",
    "unique_classes = np.unique(y_train_insurance)\n",
    "num_classes = len(unique_classes)\n",
    "print(\"Number of unique classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86bdf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique classes in your dataset\n",
    "classes = np.unique(y)\n",
    "\n",
    "\n",
    "# Check if there is only one class in your dataset\n",
    "if len(classes) == 1:\n",
    "    # Duplicate your existing class\n",
    "    X_new = np.concatenate((X, X), axis=0)\n",
    "    y_new = np.concatenate((y, y+1), axis=0)\n",
    "    \n",
    "    # Add some random noise to the duplicated class\n",
    "    noise = np.random.normal(size=(X.shape[0], X.shape[1]))\n",
    "    X_new[X.shape[0]:] += noise\n",
    "    \n",
    "    # Update your dataset\n",
    "    X = X_new\n",
    "    y = y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866e427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d704c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
